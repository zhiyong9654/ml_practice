{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code pulled in reference to https://learn.deeplearning.ai/courses/building-multimodal-search-and-rag\n",
    "course. For my own learning purposes I will deviate and make changes as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import neural network training libraries\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import basic computation libraries along with data visualization and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import umap.plot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# Import our data class which will organize MNIST and provide anchor, positive and negative samples.\n",
    "# from mnist_dataset import MNISTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n",
      "<>:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n",
      "/tmp/ipykernel_175938/84635887.py:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code copied \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, data_df: pd.DataFrame, transform=None, is_test=False):\n",
    "        # method will run once when class object is created.\n",
    "        # method will create data at the time of object creation.\n",
    "        # this will save time of training\n",
    "        super(MNISTDataset, self).__init__()\n",
    "        dataset = []\n",
    "        labels_positive = {}\n",
    "        labels_negative = {}\n",
    "        if is_test == False:\n",
    "            # for each label create a set of same label images.\n",
    "            for i in list(data_df.label.unique()):\n",
    "                labels_positive[i] = data_df[data_df.label == i].to_numpy()\n",
    "            # for each label create a set of image of different label.\n",
    "            for i in list(data_df.label.unique()):\n",
    "                labels_negative[i] = data_df[data_df.label != i].to_numpy()\n",
    "\n",
    "        for i, row in tqdm(data_df.iterrows(), total=len(data_df)):\n",
    "            data = row.to_numpy()\n",
    "            # if test then only image will be returned.\n",
    "            if is_test:\n",
    "                label = -1\n",
    "                first = data.reshape(28, 28)\n",
    "                second = -1\n",
    "                dis = -1\n",
    "            else:\n",
    "                # label and image of the index for each row in df\n",
    "                label = data[0]\n",
    "                first = data[1:].reshape(28, 28)\n",
    "                # probability of same label image == 0.5\n",
    "                if np.random.randint(0, 2) == 0:\n",
    "                    # randomly select same label image\n",
    "                    second = labels_positive[label][\n",
    "                        np.random.randint(0, len(labels_positive[label]))\n",
    "                    ]\n",
    "                else:\n",
    "                    # randomly select different(negative) label \n",
    "                    second = labels_negative[label][\n",
    "                        np.random.randint(0, len(labels_negative[label]))\n",
    "                    ]\n",
    "                # cosine is 1 for same and 0 for different label\n",
    "                dis = 1.0 if second[0] == label else 0.0\n",
    "                # reshape image\n",
    "                second = second[1:].reshape(28, 28)\n",
    "\n",
    "            # apply transform on both images\n",
    "            if transform is not None:\n",
    "                first = transform(first.astype(np.float32))\n",
    "                if second is not -1:\n",
    "                    second = transform(second.astype(np.float32))\n",
    "\n",
    "            # append to dataset list. \n",
    "            # this random list is created once and used in every epoch\n",
    "            dataset.append((first, second, dis, label))\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's important in the creation of the dataset is this:\n",
    "`dataset.append((first, second, dis, label))`\n",
    "Where \n",
    "1. `first` and `second` correspond to the embeddings of the 2 objects to compare\n",
    "2. `dis` is a value, either 0 for negative pair, or 1 for positive pair. We choose 1/0 because we plan to use cos similarity, hence perfect similarity is 1, not similar is 0.\n",
    "3. `label` is the actual label of what the first (presumably the anchor) is. I'm not sure how this extends when we have multimodality though. I.e. we have a video of a lion and a image of a lion, is label just 'lion'? How is label actually used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41000/41000 [00:19<00:00, 2115.00it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2354.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data from csv\n",
    "data = pd.read_csv('digit-recognizer/train.csv')\n",
    "val_count = 1000\n",
    "# common transformation for both val and train\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    "    transforms.Lambda(torch.flatten) # added a flatten cause i felt this makes more sense in a multi modal context, since we would have language embeddings (normally 1D)\n",
    "])\n",
    "\n",
    "# Split data into val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataloaders\n",
    "trainLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16, # feel free to modify this value\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")\n",
    "\n",
    "valLoader = DataLoader(val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 784]),\n",
       " torch.Size([16, 784]),\n",
       " tensor([0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        dtype=torch.float64),\n",
       " tensor([2, 5, 8, 1, 0, 1, 4, 6, 4, 3, 8, 0, 8, 1, 1, 3]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(trainLoader))\n",
    "# batch size x rgb channels x row x col for the 2 images.\n",
    "sample[0].shape, sample[1].shape, sample[2], sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
