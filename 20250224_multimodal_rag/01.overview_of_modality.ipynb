{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code pulled in reference to https://learn.deeplearning.ai/courses/building-multimodal-search-and-rag\n",
    "course. For my own learning purposes I will deviate and make changes as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import neural network training libraries\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import basic computation libraries along with data visualization and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import umap.plot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# Import our data class which will organize MNIST and provide anchor, positive and negative samples.\n",
    "# from mnist_dataset import MNISTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n",
      "<>:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n",
      "/tmp/ipykernel_240944/84635887.py:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code copied \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, data_df: pd.DataFrame, transform=None, is_test=False):\n",
    "        # method will run once when class object is created.\n",
    "        # method will create data at the time of object creation.\n",
    "        # this will save time of training\n",
    "        super(MNISTDataset, self).__init__()\n",
    "        dataset = []\n",
    "        labels_positive = {}\n",
    "        labels_negative = {}\n",
    "        if is_test == False:\n",
    "            # for each label create a set of same label images.\n",
    "            for i in list(data_df.label.unique()):\n",
    "                labels_positive[i] = data_df[data_df.label == i].to_numpy()\n",
    "            # for each label create a set of image of different label.\n",
    "            for i in list(data_df.label.unique()):\n",
    "                labels_negative[i] = data_df[data_df.label != i].to_numpy()\n",
    "\n",
    "        for i, row in tqdm(data_df.iterrows(), total=len(data_df)):\n",
    "            data = row.to_numpy()\n",
    "            # if test then only image will be returned.\n",
    "            if is_test:\n",
    "                label = -1\n",
    "                first = data.reshape(28, 28)\n",
    "                second = -1\n",
    "                dis = -1\n",
    "            else:\n",
    "                # label and image of the index for each row in df\n",
    "                label = data[0]\n",
    "                first = data[1:].reshape(28, 28)\n",
    "                # probability of same label image == 0.5\n",
    "                if np.random.randint(0, 2) == 0:\n",
    "                    # randomly select same label image\n",
    "                    second = labels_positive[label][\n",
    "                        np.random.randint(0, len(labels_positive[label]))\n",
    "                    ]\n",
    "                else:\n",
    "                    # randomly select different(negative) label \n",
    "                    second = labels_negative[label][\n",
    "                        np.random.randint(0, len(labels_negative[label]))\n",
    "                    ]\n",
    "                # cosine is 1 for same and 0 for different label\n",
    "                dis = 1.0 if second[0] == label else 0.0\n",
    "                # reshape image\n",
    "                second = second[1:].reshape(28, 28)\n",
    "\n",
    "            # apply transform on both images\n",
    "            if transform is not None:\n",
    "                first = transform(first.astype(np.float32))\n",
    "                if second is not -1:\n",
    "                    second = transform(second.astype(np.float32))\n",
    "\n",
    "            # append to dataset list. \n",
    "            # this random list is created once and used in every epoch\n",
    "            dataset.append((first, second, dis, label))\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's important in the creation of the dataset is this:\n",
    "`dataset.append((first, second, dis, label))`\n",
    "Where \n",
    "1. `first` and `second` correspond to the embeddings of the 2 objects to compare\n",
    "2. `dis` is a value, either 0 for negative pair, or 1 for positive pair. We choose 1/0 because we plan to use cos similarity, hence perfect similarity is 1, not similar is 0.\n",
    "3. `label` is the actual label of what the first (presumably the anchor) is. I'm not sure how this extends when we have multimodality though. I.e. we have a video of a lion and a image of a lion, is label just 'lion'? How is label actually used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41000/41000 [00:19<00:00, 2152.60it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2141.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data from csv\n",
    "data = pd.read_csv('digit-recognizer/train.csv')\n",
    "val_count = 1000\n",
    "# common transformation for both val and train\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    "    transforms.Lambda(lambda x: torch.flatten(x).unsqueeze(0)) # flatten to 1d cause i felt this makes more sense in a multi modal context, since we would have language embeddings (normally 1D)\n",
    "])\n",
    "\n",
    "# Split data into val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataloaders\n",
    "trainLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16, # feel free to modify this value\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")\n",
    "\n",
    "valLoader = DataLoader(val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 784]),\n",
       " torch.Size([16, 1, 784]),\n",
       " tensor([0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        dtype=torch.float64),\n",
       " tensor([9, 4, 2, 9, 3, 2, 5, 2, 5, 3, 8, 7, 0, 6, 8, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(trainLoader))\n",
    "# batch size x rgb channels x row x col for the 2 images.\n",
    "sample[0].shape, sample[1].shape, sample[2], sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to display images with labels\n",
    "def show_images(images, title=''):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(9, 3))\n",
    "    for i in range(num_images):\n",
    "        img = images[i].reshape(28, 28)  # reshape back, since flattened\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some examples\n",
    "for batch_idx, (anchor_images, contrastive_images, distances, labels) in enumerate(trainLoader):\n",
    "    # Convert tensors to numpy arrays\n",
    "    anchor_images = anchor_images.numpy()\n",
    "    contrastive_images = contrastive_images.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    # Display some samples from the batch\n",
    "    show_images(anchor_images[:4], title='Anchor Image')\n",
    "    show_images(contrastive_images[:4], title='+/- Example')\n",
    "    \n",
    "    # Break after displaying one batch for demonstration\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self write NN arch, 2 conv layers, 2 fc layers.\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv1d(1, 4, 3, padding=1), # 4 x 784\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2), # 4 x 392, / 2\n",
    "            nn.Conv1d(4, 8, 3, padding=1), # 8 x 392\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2), # 8 x 196\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 196, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128), # made a mistake here I set it to 10 out of habit, but we want embedding so this should be embedding dims\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write own loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cos_similarity = nn.CosineSimilarity()\n",
    "    \n",
    "    def forward(self, anchor, contrastive, distance):\n",
    "        sim = self.cos_similarity(anchor, contrastive) # get cos similarity between the 2 embeddings\n",
    "        # distance is the ideal value. 1 if anchor and contrastive is identical, 0 vice versa hence,\n",
    "        loss = torch.abs(distance - sim) # I implemented l1 loss, instead of l2 loss in the example\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will copy the below, since it's pretty boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    \n",
    "net = net.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training configuration\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "loss_function = ContrastiveLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a directory to save the checkpoints\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch_count=10):#\n",
    "    net = ConvNet()\n",
    "    lrs = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        epoch_loss = 0\n",
    "        batches=0\n",
    "        print('epoch -', epoch)\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        print('learning rate', lrs[-1])\n",
    "    \n",
    "        for anchor, contrastive, distance, label in tqdm(trainLoader): # as expected, label isn't actually used when training.\n",
    "            batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = net(anchor.to(device))\n",
    "            contrastive_out = net(contrastive.to(device))\n",
    "            distance = distance.to(torch.float32).to(device)\n",
    "            loss = loss_function(anchor_out, contrastive_out, distance)\n",
    "            epoch_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(epoch_loss.cpu().detach().numpy() / batches)\n",
    "        scheduler.step()\n",
    "        print('epoch_loss', losses[-1])\n",
    "    \n",
    "        # Save a checkpoint of the model\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "        torch.save(net.state_dict(), checkpoint_path)\n",
    "\n",
    "    return {\n",
    "        \"net\": net,\n",
    "        \"losses\": losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 26/2563 [00:18<29:39,  1.43it/s]"
     ]
    }
   ],
   "source": [
    "result = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
