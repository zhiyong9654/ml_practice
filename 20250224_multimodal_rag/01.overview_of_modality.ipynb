{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code pulled in reference to https://learn.deeplearning.ai/courses/building-multimodal-search-and-rag\n",
    "course. For my own learning purposes I will deviate and make changes as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/multimodal_rag/lib/python3.10/site-packages/numba/np/ufunc/dufunc.py:344: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import neural network training libraries\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import basic computation libraries along with data visualization and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import umap.plot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# Import our data class which will organize MNIST and provide anchor, positive and negative samples.\n",
    "# from mnist_dataset import MNISTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n",
      "<>:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n",
      "/tmp/ipykernel_1165/84635887.py:55: SyntaxWarning:\n",
      "\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code copied \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, data_df: pd.DataFrame, transform=None, is_test=False):\n",
    "        # method will run once when class object is created.\n",
    "        # method will create data at the time of object creation.\n",
    "        # this will save time of training\n",
    "        super(MNISTDataset, self).__init__()\n",
    "        dataset = []\n",
    "        labels_positive = {}\n",
    "        labels_negative = {}\n",
    "        if is_test == False:\n",
    "            # for each label create a set of same label images.\n",
    "            for i in list(data_df.label.unique()):\n",
    "                labels_positive[i] = data_df[data_df.label == i].to_numpy()\n",
    "            # for each label create a set of image of different label.\n",
    "            for i in list(data_df.label.unique()):\n",
    "                labels_negative[i] = data_df[data_df.label != i].to_numpy()\n",
    "\n",
    "        for i, row in tqdm(data_df.iterrows(), total=len(data_df)):\n",
    "            data = row.to_numpy()\n",
    "            # if test then only image will be returned.\n",
    "            if is_test:\n",
    "                label = -1\n",
    "                first = data.reshape(28, 28)\n",
    "                second = -1\n",
    "                dis = -1\n",
    "            else:\n",
    "                # label and image of the index for each row in df\n",
    "                label = data[0]\n",
    "                first = data[1:].reshape(28, 28)\n",
    "                # probability of same label image == 0.5\n",
    "                if np.random.randint(0, 2) == 0:\n",
    "                    # randomly select same label image\n",
    "                    second = labels_positive[label][\n",
    "                        np.random.randint(0, len(labels_positive[label]))\n",
    "                    ]\n",
    "                else:\n",
    "                    # randomly select different(negative) label \n",
    "                    second = labels_negative[label][\n",
    "                        np.random.randint(0, len(labels_negative[label]))\n",
    "                    ]\n",
    "                # cosine is 1 for same and 0 for different label\n",
    "                dis = 1.0 if second[0] == label else 0.0\n",
    "                # reshape image\n",
    "                second = second[1:].reshape(28, 28)\n",
    "\n",
    "            # apply transform on both images\n",
    "            if transform is not None:\n",
    "                first = transform(first.astype(np.float32))\n",
    "                if second is not -1:\n",
    "                    second = transform(second.astype(np.float32))\n",
    "\n",
    "            # append to dataset list. \n",
    "            # this random list is created once and used in every epoch\n",
    "            dataset.append((first, second, dis, label))\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.dataset[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's important in the creation of the dataset is this:\n",
    "`dataset.append((first, second, dis, label))`\n",
    "Where \n",
    "1. `first` and `second` correspond to the embeddings of the 2 objects to compare\n",
    "2. `dis` is a value, either 0 for negative pair, or 1 for positive pair. We choose 1/0 because we plan to use cos similarity, hence perfect similarity is 1, not similar is 0.\n",
    "3. `label` is the actual label of what the first (presumably the anchor) is. I'm not sure how this extends when we have multimodality though. I.e. we have a video of a lion and a image of a lion, is label just 'lion'? How is label actually used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41000/41000 [00:10<00:00, 3956.36it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4328.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data from csv\n",
    "data = pd.read_csv('digit-recognizer/train.csv')\n",
    "val_count = 1000\n",
    "# common transformation for both val and train\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    "    # transforms.Lambda(lambda x: torch.flatten(x).unsqueeze(0)) # flatten to 1d cause i felt this makes more sense in a multi modal context, since we would have language embeddings (normally 1D)\n",
    "])\n",
    "\n",
    "# Split data into val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataloaders\n",
    "trainLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16, # feel free to modify this value\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")\n",
    "\n",
    "valLoader = DataLoader(val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 28, 28]),\n",
       " torch.Size([16, 1, 28, 28]),\n",
       " tensor([0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.],\n",
       "        dtype=torch.float64),\n",
       " tensor([3, 5, 2, 1, 7, 3, 2, 4, 2, 9, 1, 1, 7, 4, 0, 9]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(trainLoader))\n",
    "# batch size x rgb channels x row x col for the 2 images.\n",
    "sample[0].shape, sample[1].shape, sample[2], sample[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to display images with labels\n",
    "def show_images(images, title=''):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(9, 3))\n",
    "    for i in range(num_images):\n",
    "        img = images[i].reshape(28, 28)  # reshape back, since flattened\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some examples\n",
    "for batch_idx, (anchor_images, contrastive_images, distances, labels) in enumerate(trainLoader):\n",
    "    # Convert tensors to numpy arrays\n",
    "    anchor_images = anchor_images.numpy()\n",
    "    contrastive_images = contrastive_images.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    # Display some samples from the batch\n",
    "    show_images(anchor_images[:4], title='Anchor Image')\n",
    "    show_images(contrastive_images[:4], title='+/- Example')\n",
    "    \n",
    "    # Break after displaying one batch for demonstration\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self write NN arch, 2 conv layers, 2 fc layers.\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "        #     nn.Conv2d(1, 32, 5, padding='same'), # 32 x 28 x 28\n",
    "        #     nn.BatchNorm2d(32),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.MaxPool2d((2, 2), stride=2), # 32 x 14 x 14\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Conv2d(32, 64, 5, padding='same'), # 64 x 14 x 14\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.MaxPool2d((2, 2), stride=2), # 64 x 7 x 7\n",
    "        #     nn.Dropout(0.3),\n",
    "        # )\n",
    "            nn.Conv1d(1, 32, 3, padding=1), # 32 x 784\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2), # 32 x 392\n",
    "            nn.Conv1d(32, 64, 3, padding=1), # 64 x 392\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2), # 64 x 196\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 196, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128), # made a mistake here I set it to 10 out of habit, but we want embedding so this should be embedding dims\n",
    "\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # return self.network(x)\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1) # flatten to batch size x 3136\n",
    "        x = F.normalize(x)\n",
    "        # print(x.min(), x.max(), x.shape)\n",
    "        return x\n",
    "        # x = self.conv1(x) # x: d * 32 * 12 * 12\n",
    "        # x = self.conv2(x) # x: d * 64 * 4  * 4 \n",
    "        # x = x.view(x.size(0), -1) # x: d * (64*4*4)\n",
    "        # x = self.linear1(x) # x: d * 64\n",
    "        # return x\n",
    "        # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEmbedder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNEmbedder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128)  # 7x7 comes from downsampling via max pooling\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # Pass through CNN\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)  # Final embedding\n",
    "        # x = F.normalize(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write own loss\n",
    "# class ContrastiveLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.cos_similarity = nn.CosineSimilarity()\n",
    "    \n",
    "#     def forward(self, anchor, contrastive, distance):\n",
    "#         sim = self.cos_similarity(anchor, contrastive) # get cos similarity between the 2 embeddings\n",
    "#         # distance is the ideal value. 1 if anchor and contrastive is identical, 0 vice versa hence,\n",
    "#         loss = torch.abs(distance - sim) # I implemented l1 loss, instead of l2 loss in the example\n",
    "#         # print(distance, sim)\n",
    "#         return loss.mean()\n",
    "\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.similarity = nn.CosineSimilarity(dim=-1, eps=1e-7)\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, contrastive, distance):\n",
    "        # use cosine similarity from torch to get score\n",
    "        score = self.similarity(anchor, contrastive)\n",
    "        # For some reason the similarity is super high\n",
    "        # print('Cos sim must be between 0-1', score.min(), score.max())\n",
    "        # after cosine apply MSE between distance and score\n",
    "        # print(score.min(), score.max(), score.shape)\n",
    "        # For identical samples, If distance is 1, and score is 0, if distance is 1 and score is 1\n",
    "        loss_same = distance * (1 - score)  # identical, distance=1, so if score is << 1, penalize\n",
    "        loss_different = (1 - distance) * (score + self.margin)  # different, distance = 0, so if score >> 0, penalize but with a margin to force apart\n",
    "        # distance * torch.clamp(score - self.margin, min=0)\n",
    "        # loss_different = (1 - distance) * (1 - score)\n",
    "        return (loss_same + loss_different).mean()\n",
    "\n",
    "        # return nn.MSELoss()(score, distance) #Ensures that the calculated score is close to the ideal distance (1 or 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will copy the below, since it's pretty boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNNEmbedder()\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    \n",
    "net = net.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training configuration\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "loss_function = ContrastiveLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a directory to save the checkpoints\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch_count=10):#\n",
    "    net = CNNEmbedder().to(device)\n",
    "    lrs = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        epoch_loss = 0\n",
    "        batches=0\n",
    "        print('epoch -', epoch)\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        print('learning rate', lrs[-1])\n",
    "    \n",
    "        for anchor, contrastive, distance, label in tqdm(trainLoader): # as expected, label isn't actually used when training.\n",
    "            batches += 1\n",
    "            \n",
    "            anchor_out = net(anchor.to(device))\n",
    "            contrastive_out = net(contrastive.to(device))\n",
    "            distance = distance.to(torch.float32).to(device)\n",
    "            loss = loss_function(anchor_out, contrastive_out, distance)\n",
    "            epoch_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # for param in net.parameters():\n",
    "            #     print(param.grad)\n",
    "\n",
    "        losses.append(epoch_loss.cpu().detach().numpy() / batches)\n",
    "        scheduler.step()\n",
    "        print('epoch_loss', losses[-1])\n",
    "    \n",
    "        # Save a checkpoint of the model\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "        torch.save(net.state_dict(), checkpoint_path)\n",
    "\n",
    "    return {\n",
    "        \"net\": net,\n",
    "        \"losses\": losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0\n",
      "learning rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:10<00:00, 242.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.7439649\n",
      "epoch - 1\n",
      "learning rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:10<00:00, 239.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.7439986\n",
      "epoch - 2\n",
      "learning rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:11<00:00, 225.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.7440658\n",
      "epoch - 3\n",
      "learning rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:10<00:00, 242.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.74400014\n",
      "epoch - 4\n",
      "learning rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:10<00:00, 255.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.7440008\n",
      "epoch - 5\n",
      "learning rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:10<00:00, 241.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.7439653\n",
      "epoch - 6\n",
      "learning rate 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:11<00:00, 222.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.7438969\n",
      "epoch - 7\n",
      "learning rate 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:10<00:00, 235.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.74406815\n",
      "epoch - 8\n",
      "learning rate 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:10<00:00, 235.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.74403596\n",
      "epoch - 9\n",
      "learning rate 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:11<00:00, 217.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.74403316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41000/41000 [00:11<00:00, 3710.11it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4130.70it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data from csv\n",
    "data = pd.read_csv('digit-recognizer/train.csv')\n",
    "val_count = 1000\n",
    "# common transformation for both val and train\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "# Split data into val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)\n",
    "\n",
    "# Create torch dataloaders\n",
    "trainLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16, # feel free to modify this value\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")\n",
    "\n",
    "valLoader = DataLoader(val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")\n",
    "\n",
    "# Function to display images with labels\n",
    "def show_images(images, title=''):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(9, 3))\n",
    "    for i in range(num_images):\n",
    "        img = np.squeeze(images[i])\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some examples\n",
    "for batch_idx, (anchor_images, contrastive_images, distances, labels) in enumerate(trainLoader):\n",
    "    # Convert tensors to numpy arrays\n",
    "    anchor_images = anchor_images.numpy()\n",
    "    contrastive_images = contrastive_images.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    # Display some samples from the batch\n",
    "    show_images(anchor_images[:4], title='Anchor Image')\n",
    "    show_images(contrastive_images[:4], title='+/- Example')\n",
    "    \n",
    "    # Break after displaying one batch for demonstration\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network architecture with two convolution layers and two fully connected layers\n",
    "# Input to the network is an MNIST image and Output is a 64 dimensional representation. \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 64),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # x: d * 32 * 12 * 12\n",
    "        x = self.conv2(x) # x: d * 64 * 4  * 4 \n",
    "        x = x.view(x.size(0), -1) # x: d * (64*4*4)\n",
    "        x = self.linear1(x) # x: d * 64\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ideal distance metric for a positive sample is set to 1, for a negative sample it is set to 0      \n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.similarity = nn.CosineSimilarity(dim=-1, eps=1e-7)\n",
    "\n",
    "    def forward(self, anchor, contrastive, distance):\n",
    "        # use cosine similarity from torch to get score\n",
    "        score = self.similarity(anchor, contrastive)\n",
    "        # after cosine apply MSE between distance and score\n",
    "        return nn.MSELoss()(score, distance) #Ensures that the calculated score is close to the ideal distance (1 or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network()\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    \n",
    "net = net.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training configuration\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "loss_function = ContrastiveLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a directory to save the checkpoints\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch_count=10):#\n",
    "    net = Network().to(device)\n",
    "    lrs = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        epoch_loss = 0\n",
    "        batches=0\n",
    "        print('epoch -', epoch)\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        print('learning rate', lrs[-1])\n",
    "    \n",
    "        for anchor, contrastive, distance, label in tqdm(trainLoader):\n",
    "            batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = net(anchor.to(device))\n",
    "            contrastive_out = net(contrastive.to(device))\n",
    "            distance = distance.to(torch.float32).to(device)\n",
    "            loss = loss_function(anchor_out, contrastive_out, distance)\n",
    "            epoch_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(epoch_loss.cpu().detach().numpy() / batches)\n",
    "        scheduler.step()\n",
    "        print('epoch_loss', losses[-1])\n",
    "    \n",
    "        # Save a checkpoint of the model\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "        torch.save(net.state_dict(), checkpoint_path)\n",
    "\n",
    "    return {\n",
    "        \"net\": net,\n",
    "        \"losses\": losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint():\n",
    "    checkpoint = torch.load('checkpoints/model_epoch_99.pt')\n",
    "    \n",
    "    net = Network()\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.eval()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:15<00:00, 160.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.2635808\n",
      "epoch - 1\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:15<00:00, 167.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.26305062\n",
      "epoch - 2\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:16<00:00, 159.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.2624549\n",
      "epoch - 3\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:15<00:00, 163.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.26228413\n",
      "epoch - 4\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:16<00:00, 159.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.26245418\n",
      "epoch - 5\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:14<00:00, 171.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.2625738\n",
      "epoch - 6\n",
      "learning rate 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:15<00:00, 169.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.2620269\n",
      "epoch - 7\n",
      "learning rate 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:14<00:00, 174.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.26235965\n",
      "epoch - 8\n",
      "learning rate 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:15<00:00, 167.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.26165062\n",
      "epoch - 9\n",
      "learning rate 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2563/2563 [00:16<00:00, 151.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss 0.26193908\n"
     ]
    }
   ],
   "source": [
    "training_result = train_model()\n",
    "model = training_result[\"net\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
