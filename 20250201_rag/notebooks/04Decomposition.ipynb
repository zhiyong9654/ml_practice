{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb\n",
    "\n",
    "some deviations from the source code because i dont wanna pay for embeddings from openai, or hit openai models. All openAI integration is replaced with ollama.\n",
    "\n",
    "I also removed langsmith integration. don't think it's needed. just a frontend for LLM debugging which i can achieve with `langchain.debug = True`\n",
    "\n",
    "Decomposition - The idea is similar to multi-query but the core idea is different. Instead of a rewrite of a given query, we ask the LLM to decompose the given question into sub-questions, perform RAG and answer each subquestion, then with each subquestion and subanswer, we ask the original question to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "# Load documents\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# setting debug to true will allow us to see what is langchain actually creating\n",
    "import langchain \n",
    "langchain.debug = True \n",
    "\n",
    "# Get embedding model\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Get chat model\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything in this cell is from previous notebooks\n",
    "# Load docs from bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split docs\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Get embedding ollama model\n",
    "embed = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embed)\n",
    "\n",
    "# Set up a retriever\n",
    "embed = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "# Embed\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}, # How many to retrieve\n",
    "    search_type='mmr'       # 'similarity' by default\n",
    ")\n",
    "\n",
    "# Get llm\n",
    "llm = ChatOllama(model=\"llama3.2:3b-instruct-q5_K_M\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance the original video by applying structured output\n",
    "from pydantic import BaseModel, conlist\n",
    "\n",
    "class DecompositionModel(BaseModel):\n",
    "    questions: conlist(str, min_length=3, max_length=3)\n",
    "\n",
    "decomposition_llm = ChatOllama(\n",
    "    model=\"llama3.2:3b-instruct-q5_K_M\",\n",
    "    temperature=0,\n",
    "    format=DecompositionModel.model_json_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The part that decomposes the question\n",
    "def decomposition_validator(ai_message):\n",
    "    return DecompositionModel.model_validate_json(ai_message.content).questions\n",
    "\n",
    "decomposition_prompt = \"\"\"Decompose the following question into {n} number of subquestions that can be individually answer.\\n{question}\"\"\"\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(decomposition_prompt)\n",
    "decomposition_chain = decomposition_prompt | decomposition_llm | decomposition_validator # | StrOutputParser() | (lambda x: x.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the main components of an LLM-powered autonomous agent system?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"n\": 3,\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"n\": 3,\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Decompose the following question into 3 number of subquestions that can be individually answer.\\nWhat are the main components of an LLM-powered autonomous agent system?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [12.19s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{ \\\"questions\\\": [ \\\"What is a key component of an LLM-powered autonomous agent system?\\\", \\\"How does LLM technology contribute to the decision-making process in an autonomous agent system?\\\", \\\"What role do other AI technologies play alongside LLM in an autonomous agent system?\\\" ] }\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T13:19:26.068961114Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 12185994995,\n",
      "          \"load_duration\": 5878155163,\n",
      "          \"prompt_eval_count\": 58,\n",
      "          \"prompt_eval_duration\": 2066000000,\n",
      "          \"eval_count\": 59,\n",
      "          \"eval_duration\": 4239000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{ \\\"questions\\\": [ \\\"What is a key component of an LLM-powered autonomous agent system?\\\", \\\"How does LLM technology contribute to the decision-making process in an autonomous agent system?\\\", \\\"What role do other AI technologies play alongside LLM in an autonomous agent system?\\\" ] }\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T13:19:26.068961114Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 12185994995,\n",
      "              \"load_duration\": 5878155163,\n",
      "              \"prompt_eval_count\": 58,\n",
      "              \"prompt_eval_duration\": 2066000000,\n",
      "              \"eval_count\": 59,\n",
      "              \"eval_duration\": 4239000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-0fe946a8-1615-457e-82c9-ea8af6ff31fe-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 58,\n",
      "              \"output_tokens\": 59,\n",
      "              \"total_tokens\": 117\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:decomposition_validator] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:decomposition_validator] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "    \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "    \"What role do other AI technologies play alongside LLM in an autonomous agent system?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [12.19s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": [\n",
      "    \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "    \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "    \"What role do other AI technologies play alongside LLM in an autonomous agent system?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "questions = decomposition_chain.invoke({'n':3, 'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is a key component of an LLM-powered autonomous agent system?',\n",
       " 'How does LLM technology contribute to the decision-making process in an autonomous agent system?',\n",
       " 'What role do other AI technologies play alongside LLM in an autonomous agent system?']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7a327c7c1ea0>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is a key component of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What is a key component of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What is a key component of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence] [962ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion>] [964ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Here is the question you need to answer:\\nWhat is a key component of an LLM-powered autonomous agent system?\\n\\n\\nHere are additional related questions and answers to use to answer the question:\\n\\n\\n\\nHere is additional context relevant to the question:\\n[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='}\\\\n]\\\\nChallenges#\\\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\\\nComponent Three: Tool Use#\\\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Long-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\\\n\\\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 8. Categorization of human memory.\\\\nWe can roughly consider the following mappings:\\\\n\\\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\\\"task\\\": task, \\\"id\\\", task_id, \\\"dep\\\": dependency_task_ids, \\\"args\\\": {\\\"text\\\": text, \\\"image\\\": URL, \\\"audio\\\": URL, \\\"video\\\": URL}}]. The \\\"dep\\\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \\\"-task_id\\\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\\\n\\\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\\\nInstruction:')]\\n\\n\\nUse the above context and any related questions and answer to answer the question:\\nWhat is a key component of an LLM-powered autonomous agent system?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [39.21s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T13:38:18.172881514Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 39208518950,\n",
      "          \"load_duration\": 5588848610,\n",
      "          \"prompt_eval_count\": 1069,\n",
      "          \"prompt_eval_duration\": 28306000000,\n",
      "          \"eval_count\": 73,\n",
      "          \"eval_duration\": 5291000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T13:38:18.172881514Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 39208518950,\n",
      "              \"load_duration\": 5588848610,\n",
      "              \"prompt_eval_count\": 1069,\n",
      "              \"prompt_eval_duration\": 28306000000,\n",
      "              \"eval_count\": 73,\n",
      "              \"eval_duration\": 5291000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-53d4bba7-a506-4d81-a0f4-c16e05125019-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1069,\n",
      "              \"output_tokens\": 73,\n",
      "              \"total_tokens\": 1142\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [40.18s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"How does LLM technology contribute to the decision-making process in an autonomous agent system?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence] [39ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion>] [40ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Here is the question you need to answer:\\nHow does LLM technology contribute to the decision-making process in an autonomous agent system?\\n\\n\\nHere are additional related questions and answers to use to answer the question:\\nRelated question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\n\\nHere is additional context relevant to the question:\\n[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\\\nFor example, when requested to \\\"develop a novel anticancer drug\\\", the model came up with the following reasoning steps:\\\\n\\\\ninquired about current trends in anticancer drug discovery;\\\\nselected a target;\\\\nrequested a scaffold targeting these compounds;\\\\nOnce the compound was identified, the model attempted its synthesis.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\\\nSelf-Reflection#\\\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Whether an API call is needed.\\\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\\\n\\\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\\\n\\\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.')]\\n\\n\\nUse the above context and any related questions and answer to answer the question:\\nHow does LLM technology contribute to the decision-making process in an autonomous agent system?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [60.30s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T13:39:18.511345001Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 60293275793,\n",
      "          \"load_duration\": 38624554,\n",
      "          \"prompt_eval_count\": 1434,\n",
      "          \"prompt_eval_duration\": 37531000000,\n",
      "          \"eval_count\": 306,\n",
      "          \"eval_duration\": 22722000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T13:39:18.511345001Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 60293275793,\n",
      "              \"load_duration\": 38624554,\n",
      "              \"prompt_eval_count\": 1434,\n",
      "              \"prompt_eval_duration\": 37531000000,\n",
      "              \"eval_count\": 306,\n",
      "              \"eval_duration\": 22722000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-e1486533-2c95-4cbf-acd1-5677d358a895-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1434,\n",
      "              \"output_tokens\": 306,\n",
      "              \"total_tokens\": 1740\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [60.34s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"subquestion\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What role do other AI technologies play alongside LLM in an autonomous agent system?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion> > chain:RunnableSequence] [34ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,subquestion>] [35ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Here is the question you need to answer:\\nWhat role do other AI technologies play alongside LLM in an autonomous agent system?\\n\\n\\nHere are additional related questions and answers to use to answer the question:\\nRelated question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\n\\nHere is additional context relevant to the question:\\n[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\\\nFor example, when requested to \\\"develop a novel anticancer drug\\\", the model came up with the following reasoning steps:\\\\n\\\\ninquired about current trends in anticancer drug discovery;\\\\nselected a target;\\\\nrequested a scaffold targeting these compounds;\\\\nOnce the compound was identified, the model attempted its synthesis.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\\\"task\\\": task, \\\"id\\\", task_id, \\\"dep\\\": dependency_task_ids, \\\"args\\\": {\\\"text\\\": text, \\\"image\\\": URL, \\\"audio\\\": URL, \\\"video\\\": URL}}]. The \\\"dep\\\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \\\"-task_id\\\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\\\n\\\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\\\nInstruction:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\\\nComponent Three: Tool Use#\\\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Both TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.')]\\n\\n\\nUse the above context and any related questions and answer to answer the question:\\nWhat role do other AI technologies play alongside LLM in an autonomous agent system?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [65.96s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T13:40:24.508097587Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 65956307900,\n",
      "          \"load_duration\": 23897255,\n",
      "          \"prompt_eval_count\": 1654,\n",
      "          \"prompt_eval_duration\": 43963000000,\n",
      "          \"eval_count\": 293,\n",
      "          \"eval_duration\": 21968000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T13:40:24.508097587Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 65956307900,\n",
      "              \"load_duration\": 23897255,\n",
      "              \"prompt_eval_count\": 1654,\n",
      "              \"prompt_eval_duration\": 43963000000,\n",
      "              \"eval_count\": 293,\n",
      "              \"eval_duration\": 21968000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-77ca73fe-2a33-4135-ae65-14b83ef6dbe6-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1654,\n",
      "              \"output_tokens\": 293,\n",
      "              \"total_tokens\": 1947\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [66.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The part where you iteratively have an LLM answer the question, but adding each subquestion/subanswer\n",
    "# The video example doesn't make sense to me. Why would we answer each subquestion, but not answer the original question?\n",
    "\n",
    "subquestion_answers = []\n",
    "\n",
    "for subquestion in questions:\n",
    "    iterative_prompt_template = \"\"\"Here is the question you need to answer:\n",
    "{subquestion}\n",
    "\n",
    "\n",
    "Here are additional related questions and answers to use to answer the question:\n",
    "{subquestion_answers}\n",
    "\n",
    "\n",
    "Here is additional context relevant to the question:\n",
    "{context}\n",
    "\n",
    "\n",
    "Use the above context and any related questions and answer to answer the question:\n",
    "{subquestion}\n",
    "\"\"\"\n",
    "\n",
    "    iterative_prompt = ChatPromptTemplate.from_template(iterative_prompt_template)\n",
    "    subquestion_chain = (\n",
    "        {\n",
    "            'context': itemgetter('subquestion') | retriever,\n",
    "            'subquestion_answers': itemgetter('subquestion_answers'),\n",
    "            'subquestion': itemgetter('subquestion')\n",
    "        }\n",
    "        | iterative_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    subquestion_answer = subquestion_chain.invoke({'subquestion': subquestion, 'subquestion_answers': '\\n\\n'.join(subquestion_answers)})\n",
    "    subquestion_answers.append(f\"Related question: {subquestion}\\nRelated answer: {subquestion_answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What are the main components of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What are the main components of an LLM-powered autonomous agent system?\",\n",
      "  \"subquestion_answers\": \"Related question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"What are the main components of an LLM-powered autonomous agent system?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question> > chain:RunnableSequence] [912ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,subquestion_answers,question>] [914ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a helpful assistant. I have some context and related questions for you to read, and I need you to answer the question below:\\n\\nRelated question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\n\\nHere is additional context relevant to the question:\\n[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='}\\\\n]\\\\nChallenges#\\\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\\\n1. Internet access for searches and information gathering.\\\\n2. Long Term memory management.\\\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\\\n4. File output.\\\\n\\\\nPerformance Evaluation:\\\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\\\n2. Constructively self-criticize your big-picture behavior constantly.\\\\n3. Reflect on past decisions and strategies to refine your approach.\\\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\\\"task\\\": task, \\\"id\\\", task_id, \\\"dep\\\": dependency_task_ids, \\\"args\\\": {\\\"text\\\": text, \\\"image\\\": URL, \\\"audio\\\": URL, \\\"video\\\": URL}}]. The \\\"dep\\\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \\\"-task_id\\\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\\\n\\\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\\\nInstruction:')]\\n\\n\\nUse the above context and any related questions and answer to answer the question:\\nWhat are the main components of an LLM-powered autonomous agent system?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [71.35s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided context, the main components of a Large Language Model (LLM)-powered autonomous agent system are:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nThese components work together to enable an LLM-powered autonomous agent system to make informed decisions by providing a powerful general problem solver that can break down complex tasks into smaller steps, reflect on past actions, and store knowledge for future use.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T13:53:52.259844193Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 71343798119,\n",
      "          \"load_duration\": 5091420135,\n",
      "          \"prompt_eval_count\": 1878,\n",
      "          \"prompt_eval_duration\": 51685000000,\n",
      "          \"eval_count\": 187,\n",
      "          \"eval_duration\": 14565000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided context, the main components of a Large Language Model (LLM)-powered autonomous agent system are:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nThese components work together to enable an LLM-powered autonomous agent system to make informed decisions by providing a powerful general problem solver that can break down complex tasks into smaller steps, reflect on past actions, and store knowledge for future use.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T13:53:52.259844193Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 71343798119,\n",
      "              \"load_duration\": 5091420135,\n",
      "              \"prompt_eval_count\": 1878,\n",
      "              \"prompt_eval_duration\": 51685000000,\n",
      "              \"eval_count\": 187,\n",
      "              \"eval_duration\": 14565000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-de54e84e-d707-44c2-b229-b17d5c199c90-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1878,\n",
      "              \"output_tokens\": 187,\n",
      "              \"total_tokens\": 2065\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, the main components of a Large Language Model (LLM)-powered autonomous agent system are:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nThese components work together to enable an LLM-powered autonomous agent system to make informed decisions by providing a powerful general problem solver that can break down complex tasks into smaller steps, reflect on past actions, and store knowledge for future use.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [72.27s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Based on the provided context, the main components of a Large Language Model (LLM)-powered autonomous agent system are:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nThese components work together to enable an LLM-powered autonomous agent system to make informed decisions by providing a powerful general problem solver that can break down complex tasks into smaller steps, reflect on past actions, and store knowledge for future use.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# will enhance the example from video by doing an additional prompt combining the subquestions and answers back with the original question:\n",
    "\n",
    "final_prompt_template = \"\"\"You are a helpful assistant. I have some context and related questions for you to read, and I need you to answer the question below:\n",
    "\n",
    "{subquestion_answers}\n",
    "\n",
    "\n",
    "Here is additional context relevant to the question:\n",
    "{context}\n",
    "\n",
    "\n",
    "Use the above context and any related questions and answer to answer the question:\n",
    "{question}\n",
    "\"\"\"\n",
    "final_prompt = ChatPromptTemplate.from_template(final_prompt_template)\n",
    "final_chain = (\n",
    "    {\n",
    "        'context': itemgetter('question') | retriever,\n",
    "        'subquestion_answers': itemgetter('subquestion_answers'),\n",
    "        'question': itemgetter('question')\n",
    "    }\n",
    "    | final_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "final_answer = final_chain.invoke({'question': question, 'subquestion_answers': '\\n\\n'.join(subquestion_answers)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant. I have some context and related questions for you to read, and I need you to answer the question below:\n",
      "\n",
      "Related question: What is a key component of an LLM-powered autonomous agent system?\n",
      "Related answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\n",
      "\n",
      "Related question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\n",
      "Related answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\n",
      "\n",
      "1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\n",
      "3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\n",
      "\n",
      "In terms of decision-making, LLM technology contributes by:\n",
      "\n",
      "1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\n",
      "2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\n",
      "3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\n",
      "\n",
      "Overall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\n",
      "\n",
      "Related question: What role do other AI technologies play alongside LLM in an autonomous agent system?\n",
      "Related answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\n",
      "\n",
      "1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\n",
      "3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\n",
      "\n",
      "Additionally, other AI technologies such as:\n",
      "\n",
      "* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\n",
      "* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\n",
      "* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\n",
      "\n",
      "These technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\n",
      "\n",
      "\n",
      "Here is additional context relevant to the question:\n",
      "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:')]\n",
      "\n",
      "\n",
      "Use the above context and any related questions and answer to answer the question:\n",
      "What are the main components of an LLM-powered autonomous agent system?\n"
     ]
    }
   ],
   "source": [
    "print(\"You are a helpful assistant. I have some context and related questions for you to read, and I need you to answer the question below:\\n\\nRelated question: What is a key component of an LLM-powered autonomous agent system?\\nRelated answer: Based on the provided context, a key component of an LLM-powered autonomous agent system is Long-Term Memory (LTM). LTM can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. It consists of two subtypes: Explicit/Declarative memory and Implicit/Procedural memory.\\n\\nRelated question: How does LLM technology contribute to the decision-making process in an autonomous agent system?\\nRelated answer: Based on the provided context, LLM (Large Language Model) technology contributes to the decision-making process in an autonomous agent system through several key components:\\n\\n1. **Planning**: LLM helps break down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: LLM allows for self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nIn terms of decision-making, LLM technology contributes by:\\n\\n1. **Generating reasoning traces in natural language**: LLM can generate reasoning traces that help the agent understand its own thought process and identify areas for improvement.\\n2. **Providing self-reflection prompts**: The ReAct prompt template enables LLM to think explicitly about its actions and decisions, allowing the agent to reflect on its past choices and refine them for future steps.\\n3. **Evaluating task results**: LLM can evaluate the correctness of task results, identifying areas where the agent needs to improve.\\n\\nOverall, LLM technology plays a crucial role in enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\nRelated question: What role do other AI technologies play alongside LLM in an autonomous agent system?\\nRelated answer: Based on the provided context, other AI technologies play several key roles alongside Large Language Models (LLMs) in a LLM-powered autonomous agent system:\\n\\n1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\\n3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\\n\\nAdditionally, other AI technologies such as:\\n\\n* **Model selection**: LLM distributes tasks to expert models, where the request is framed as a multiple-choice question.\\n* **Tool use**: Equipping LLMs with external tools can significantly extend the model capabilities. This includes fine-tuning a LM to learn to use external tool APIs (TALM and Toolformer).\\n* **Plugin development**: The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\n\\nThese technologies complement LLMs, enabling autonomous agents to make informed decisions by providing a powerful general problem solver that can break down complex tasks into manageable subgoals, reflect on past actions, and learn from mistakes.\\n\\n\\nHere is additional context relevant to the question:\\n[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='}\\\\n]\\\\nChallenges#\\\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Resources:\\\\n1. Internet access for searches and information gathering.\\\\n2. Long Term memory management.\\\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\\\n4. File output.\\\\n\\\\nPerformance Evaluation:\\\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\\\n2. Constructively self-criticize your big-picture behavior constantly.\\\\n3. Reflect on past decisions and strategies to refine your approach.\\\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\\\"task\\\": task, \\\"id\\\", task_id, \\\"dep\\\": dependency_task_ids, \\\"args\\\": {\\\"text\\\": text, \\\"image\\\": URL, \\\"audio\\\": URL, \\\"video\\\": URL}}]. The \\\"dep\\\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \\\"-task_id\\\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\\\n\\\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\\\nInstruction:')]\\n\\n\\nUse the above context and any related questions and answer to answer the question:\\nWhat are the main components of an LLM-powered autonomous agent system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the main components of a Large Language Model (LLM)-powered autonomous agent system are:\n",
      "\n",
      "1. **Planning**: Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes and refining them for future steps, thereby improving the quality of final results.\n",
      "3. **Memory**: Long-Term Memory (LTM) can store information for a remarkably long time, ranging from a few days to decades, with essentially unlimited storage capacity. This enables the agent to retain knowledge and learn from past experiences.\n",
      "\n",
      "These components work together to enable an LLM-powered autonomous agent system to make informed decisions by providing a powerful general problem solver that can break down complex tasks into smaller steps, reflect on past actions, and store knowledge for future use.\n"
     ]
    }
   ],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
