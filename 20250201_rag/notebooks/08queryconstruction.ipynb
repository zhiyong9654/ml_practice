{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb\n",
    "\n",
    "some deviations from the source code because i dont wanna pay for embeddings from openai, or hit openai models. All openAI integration is replaced with ollama.\n",
    "\n",
    "I also removed langsmith integration. don't think it's needed. just a frontend for LLM debugging which i can achieve with `langchain.debug = True`\n",
    "\n",
    "For query structuring i'll deviate quite heavily from the notebook above as the methods applied are quite trivial to implement, will attempt to implement a custom example myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain \n",
    "langchain.debug = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic.types import confloat\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from typing import Optional, Literal\n",
    "from langchain_ollama.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_structured_prompt_template = \"\"\"You are an expert at converting the users questions into database queries.\n",
    "You have access to a database of restaurants. Given a search query in natural language, return a structured output for use in database search. \n",
    "\n",
    "This is the pydantic definition of the search query:\n",
    "    cuisine: Literal['french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'] = Field(\n",
    "        ..., # ... means a mandatory field\n",
    "        description=\"The type of cuisine the restaurant should serve: 'french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'\"\n",
    "    )\n",
    "    ratings: Optional[confloat(ge=1, le=5)] = Field(\n",
    "        None,\n",
    "        description='The ratings/stars that restaurant should have from 1 to 5, with 5 being the best.'\n",
    "    ),\n",
    "    price_point: Optional[Literal['$', '$$', '$$$', '$$$$', '$$$$$']] = Field(\n",
    "        None,\n",
    "        description=\"The price point of the restaurant, as '$', '$$', '$$$', '$$$$', '$$$$$' with '$$$$$' being the most expensive.\"\n",
    "    ),\n",
    "    reason: str = Field(\n",
    "        ...,\n",
    "        description=\"How the user question related to the cuisine\"\n",
    "    )\n",
    "\n",
    "user question:\n",
    "{user_question}\n",
    "\"\"\"\n",
    "\n",
    "db_structured_prompt = ChatPromptTemplate.from_template(db_structured_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/rag/lib/python3.10/site-packages/pydantic/json_schema.py:2279: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None, description='The ratings/stars that restaurant should have from 1 to 5, with 5 being the best.'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/home/zhiyong/.pyenv/versions/3.10.4/envs/rag/lib/python3.10/site-packages/pydantic/json_schema.py:2279: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=False, default=None, description=\"The price point of the restaurant, as '$', '$$', '$$$', '$$$$', '$$$$$' with '$$$$$' being the most expensive.\"),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "class RestaurantSearch(BaseModel):\n",
    "    cuisine: Literal['french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'] = Field(\n",
    "        ..., # ... means a mandatory field\n",
    "        description=\"The type of cuisine the restaurant should serve: 'french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'\"\n",
    "    )\n",
    "    ratings: Optional[confloat(ge=1, le=5)] = Field(\n",
    "        None,\n",
    "        description='The ratings/stars that restaurant should have from 1 to 5, with 5 being the best.'\n",
    "    ),\n",
    "    price_point: Optional[Literal['$', '$$', '$$$', '$$$$', '$$$$$']] = Field(\n",
    "        None,\n",
    "        description=\"The price point of the restaurant, as '$', '$$', '$$$', '$$$$', '$$$$$' with '$$$$$' being the most expensive.\"\n",
    "    ),\n",
    "    reason: str = Field(\n",
    "        ...,\n",
    "        description=\"How the user question related to the cuisine\"\n",
    "    )\n",
    "\n",
    "rest_structured_llm = ChatOllama(\n",
    "    model=\"llama3.2:3b-instruct-q5_K_M\",\n",
    "    temperature=0,\n",
    "    format=RestaurantSearch.model_json_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"user_question\": \"cheap tacos with >3.5 star\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"user_question\": \"cheap tacos with >3.5 star\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at converting the users questions into database queries.\\nYou have access to a database of restaurants. Given a search query in natural language, return a structured output for use in database search. \\n\\nThis is the pydantic definition of the search query:\\n    cuisine: Literal['french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'] = Field(\\n        ..., # ... means a mandatory field\\n        description=\\\"The type of cuisine the restaurant should serve: 'french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'\\\"\\n    )\\n    ratings: Optional[confloat(ge=1, le=5)] = Field(\\n        None,\\n        description='The ratings/stars that restaurant should have from 1 to 5, with 5 being the best.'\\n    ),\\n    price_point: Optional[Literal['$', '$$', '$$$', '$$$$', '$$$$$']] = Field(\\n        None,\\n        description=\\\"The price point of the restaurant, as '$', '$$', '$$$', '$$$$', '$$$$$' with '$$$$$' being the most expensive.\\\"\\n    ),\\n    reason: str = Field(\\n        ...,\\n        description=\\\"How the user question related to the cuisine\\\"\\n    )\\n\\nuser question:\\ncheap tacos with >3.5 star\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [2.66s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{ \\\"cuisine\\\": \\\"mexican\\\", \\\"reason\\\": \\\"cheap tacos\\\", \\\"ratings\\\": 3.5, \\\"price_point\\\": \\\"$$\\\" }\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-09T07:04:22.198278168Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 2656763941,\n",
      "          \"load_duration\": 33997542,\n",
      "          \"prompt_eval_count\": 316,\n",
      "          \"prompt_eval_duration\": 406000000,\n",
      "          \"eval_count\": 33,\n",
      "          \"eval_duration\": 2215000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{ \\\"cuisine\\\": \\\"mexican\\\", \\\"reason\\\": \\\"cheap tacos\\\", \\\"ratings\\\": 3.5, \\\"price_point\\\": \\\"$$\\\" }\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-09T07:04:22.198278168Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 2656763941,\n",
      "              \"load_duration\": 33997542,\n",
      "              \"prompt_eval_count\": 316,\n",
      "              \"prompt_eval_duration\": 406000000,\n",
      "              \"eval_count\": 33,\n",
      "              \"eval_duration\": 2215000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-7c43d5a1-1cae-479e-a16c-a3abf1c19cb8-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 316,\n",
      "              \"output_tokens\": 33,\n",
      "              \"total_tokens\": 349\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"cuisine\": \"mexican\",\n",
      "  \"reason\": \"cheap tacos\",\n",
      "  \"ratings\": 3.5,\n",
      "  \"price_point\": \"$$\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.66s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"cuisine\": \"mexican\",\n",
      "  \"reason\": \"cheap tacos\",\n",
      "  \"ratings\": 3.5,\n",
      "  \"price_point\": \"$$\"\n",
      "}\n",
      "{'cuisine': 'mexican', 'reason': 'cheap tacos', 'ratings': 3.5, 'price_point': '$$'}\n"
     ]
    }
   ],
   "source": [
    "chain = db_structured_prompt | rest_structured_llm | JsonOutputParser()\n",
    "\n",
    "print(chain.invoke({'user_question': \"cheap tacos with >3.5 star\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"user_question\": \"value for money tacos with >3.5 star\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"user_question\": \"value for money tacos with >3.5 star\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at converting the users questions into database queries.\\nYou have access to a database of restaurants. Given a search query in natural language, return a structured output for use in database search. \\n\\nThis is the pydantic definition of the search query:\\n    cuisine: Literal['french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'] = Field(\\n        ..., # ... means a mandatory field\\n        description=\\\"The type of cuisine the restaurant should serve: 'french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'\\\"\\n    )\\n    ratings: Optional[confloat(ge=1, le=5)] = Field(\\n        None,\\n        description='The ratings/stars that restaurant should have from 1 to 5, with 5 being the best.'\\n    ),\\n    price_point: Optional[Literal['$', '$$', '$$$', '$$$$', '$$$$$']] = Field(\\n        None,\\n        description=\\\"The price point of the restaurant, as '$', '$$', '$$$', '$$$$', '$$$$$' with '$$$$$' being the most expensive.\\\"\\n    ),\\n    reason: str = Field(\\n        ...,\\n        description=\\\"How the user question related to the cuisine\\\"\\n    )\\n\\nuser question:\\nvalue for money tacos with >3.5 star\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [2.78s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{ \\\"cuisine\\\": \\\"mexican\\\", \\\"reason\\\": \\\"value for money\\\", \\\"ratings\\\": 3.5, \\\"price_point\\\": \\\"$$\\\" }\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-09T07:04:24.989069455Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 2781751319,\n",
      "          \"load_duration\": 17416408,\n",
      "          \"prompt_eval_count\": 318,\n",
      "          \"prompt_eval_duration\": 430000000,\n",
      "          \"eval_count\": 34,\n",
      "          \"eval_duration\": 2332000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{ \\\"cuisine\\\": \\\"mexican\\\", \\\"reason\\\": \\\"value for money\\\", \\\"ratings\\\": 3.5, \\\"price_point\\\": \\\"$$\\\" }\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-09T07:04:24.989069455Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 2781751319,\n",
      "              \"load_duration\": 17416408,\n",
      "              \"prompt_eval_count\": 318,\n",
      "              \"prompt_eval_duration\": 430000000,\n",
      "              \"eval_count\": 34,\n",
      "              \"eval_duration\": 2332000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-432407ca-4c55-41a7-b9c3-e6640307e198-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 318,\n",
      "              \"output_tokens\": 34,\n",
      "              \"total_tokens\": 352\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"cuisine\": \"mexican\",\n",
      "  \"reason\": \"value for money\",\n",
      "  \"ratings\": 3.5,\n",
      "  \"price_point\": \"$$\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.79s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"cuisine\": \"mexican\",\n",
      "  \"reason\": \"value for money\",\n",
      "  \"ratings\": 3.5,\n",
      "  \"price_point\": \"$$\"\n",
      "}\n",
      "{'cuisine': 'mexican', 'reason': 'value for money', 'ratings': 3.5, 'price_point': '$$'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'user_question': \"value for money tacos with >3.5 star\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"user_question\": \"upscale restaurant with har cheong gai with more than 4.2 star\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"user_question\": \"upscale restaurant with har cheong gai with more than 4.2 star\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an expert at converting the users questions into database queries.\\nYou have access to a database of restaurants. Given a search query in natural language, return a structured output for use in database search. \\n\\nThis is the pydantic definition of the search query:\\n    cuisine: Literal['french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'] = Field(\\n        ..., # ... means a mandatory field\\n        description=\\\"The type of cuisine the restaurant should serve: 'french', 'chinese', 'mexican', 'thai', 'indian', 'english', 'african', 'na'\\\"\\n    )\\n    ratings: Optional[confloat(ge=1, le=5)] = Field(\\n        None,\\n        description='The ratings/stars that restaurant should have from 1 to 5, with 5 being the best.'\\n    ),\\n    price_point: Optional[Literal['$', '$$', '$$$', '$$$$', '$$$$$']] = Field(\\n        None,\\n        description=\\\"The price point of the restaurant, as '$', '$$', '$$$', '$$$$', '$$$$$' with '$$$$$' being the most expensive.\\\"\\n    ),\\n    reason: str = Field(\\n        ...,\\n        description=\\\"How the user question related to the cuisine\\\"\\n    )\\n\\nuser question:\\nupscale restaurant with har cheong gai with more than 4.2 star\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [3.11s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{ \\\"cuisine\\\": \\\"chinese\\\", \\\"reason\\\": \\\"har cheong gai\\\", \\\"ratings\\\": 4.2, \\\"price_point\\\": \\\"$$$\\\" }\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-09T07:04:44.334024022Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 3101458857,\n",
      "          \"load_duration\": 32022520,\n",
      "          \"prompt_eval_count\": 325,\n",
      "          \"prompt_eval_duration\": 504000000,\n",
      "          \"eval_count\": 36,\n",
      "          \"eval_duration\": 2564000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{ \\\"cuisine\\\": \\\"chinese\\\", \\\"reason\\\": \\\"har cheong gai\\\", \\\"ratings\\\": 4.2, \\\"price_point\\\": \\\"$$$\\\" }\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-09T07:04:44.334024022Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 3101458857,\n",
      "              \"load_duration\": 32022520,\n",
      "              \"prompt_eval_count\": 325,\n",
      "              \"prompt_eval_duration\": 504000000,\n",
      "              \"eval_count\": 36,\n",
      "              \"eval_duration\": 2564000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ba62255c-5ead-4d7f-9dab-7921ba54a1a2-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 325,\n",
      "              \"output_tokens\": 36,\n",
      "              \"total_tokens\": 361\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"cuisine\": \"chinese\",\n",
      "  \"reason\": \"har cheong gai\",\n",
      "  \"ratings\": 4.2,\n",
      "  \"price_point\": \"$$$\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [3.11s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"cuisine\": \"chinese\",\n",
      "  \"reason\": \"har cheong gai\",\n",
      "  \"ratings\": 4.2,\n",
      "  \"price_point\": \"$$$\"\n",
      "}\n",
      "{'cuisine': 'chinese', 'reason': 'har cheong gai', 'ratings': 4.2, 'price_point': '$$$'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'user_question': \"upscale restaurant with har cheong gai with more than 4.2 star\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
