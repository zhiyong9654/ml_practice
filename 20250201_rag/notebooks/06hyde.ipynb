{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb\n",
    "\n",
    "some deviations from the source code because i dont wanna pay for embeddings from openai, or hit openai models. All openAI integration is replaced with ollama.\n",
    "\n",
    "I also removed langsmith integration. don't think it's needed. just a frontend for LLM debugging which i can achieve with `langchain.debug = True`\n",
    "\n",
    "HyDE - For RAGs, we normally retrieve documents by comparing embeddings with the question. But a question is written in the style of each user and typically quite different from the documents to which it's compared against.\n",
    "\n",
    "To resolve this HyDE attempts to ask a LLM to create a hypothetical document, based on your input question, then perform a Retrieval search using this hypothetical document instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "# Load documents\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# setting debug to true will allow us to see what is langchain actually creating\n",
    "import langchain \n",
    "langchain.debug = True \n",
    "\n",
    "# Get embedding model\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Get chat model\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything in this cell is from previous notebooks\n",
    "# Load docs from bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split docs\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Get embedding ollama model\n",
    "embed = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=embed)\n",
    "\n",
    "# Set up a retriever\n",
    "embed = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "# Embed\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}, # How many to retrieve\n",
    "    search_type='mmr'       # 'similarity' by default\n",
    ")\n",
    "\n",
    "# Get llm\n",
    "llm = ChatOllama(model=\"llama3.2:3b-instruct-q5_K_M\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Please write a paper/document to answer the question:\\nQuestion: what is task decomposition for LLM agents\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [59.28s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T15:17:11.835145053Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 59270783004,\n",
      "          \"load_duration\": 58417314,\n",
      "          \"prompt_eval_count\": 45,\n",
      "          \"prompt_eval_duration\": 73000000,\n",
      "          \"eval_count\": 856,\n",
      "          \"eval_duration\": 59137000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T15:17:11.835145053Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 59270783004,\n",
      "              \"load_duration\": 58417314,\n",
      "              \"prompt_eval_count\": 45,\n",
      "              \"prompt_eval_duration\": 73000000,\n",
      "              \"eval_count\": 856,\n",
      "              \"eval_duration\": 59137000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b8ec0ecb-9a67-4db1-a610-d10cad515936-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 45,\n",
      "              \"output_tokens\": 856,\n",
      "              \"total_tokens\": 901\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [59.28s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyde_prompt_template = \"\"\"Please write a paper/document to answer the question:\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "hyde_prompt = ChatPromptTemplate.from_template(hyde_prompt_template)\n",
    "\n",
    "question = 'what is task decomposition for LLM agents'\n",
    "\n",
    "hyde_chain = (hyde_prompt | llm | StrOutputParser())\n",
    "hyde_chain.invoke({'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Please write a paper/document to answer the question:\\nQuestion: what is task decomposition for LLM agents\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"what is task decomposition for LLM agents\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatOllama] [58.70s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T15:18:10.548831789Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 58699013672,\n",
      "          \"load_duration\": 17806520,\n",
      "          \"prompt_eval_count\": 45,\n",
      "          \"prompt_eval_duration\": 63000000,\n",
      "          \"eval_count\": 856,\n",
      "          \"eval_duration\": 58616000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T15:18:10.548831789Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 58699013672,\n",
      "              \"load_duration\": 17806520,\n",
      "              \"prompt_eval_count\": 45,\n",
      "              \"prompt_eval_duration\": 63000000,\n",
      "              \"eval_count\": 856,\n",
      "              \"eval_duration\": 58616000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b49fea47-c183-47e2-8e94-0765849780d8-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 45,\n",
      "              \"output_tokens\": 856,\n",
      "              \"total_tokens\": 901\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"**Task Decomposition for Large Language Model (LLM) Agents**\\n\\n**Abstract**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that involves breaking down complex tasks into smaller, manageable sub-tasks. In the context of Large Language Model (LLM) agents, task decomposition plays a vital role in enabling these agents to perform a wide range of cognitive and decision-making tasks. This paper provides an overview of task decomposition for LLM agents, including its importance, benefits, and challenges.\\n\\n**Introduction**\\n\\nLarge Language Models (LLMs) have revolutionized the field of artificial intelligence by achieving state-of-the-art performance in various natural language processing (NLP) tasks. However, these models are typically trained on large datasets and lack the ability to generalize to new, unseen tasks. Task decomposition is a technique that addresses this limitation by breaking down complex tasks into smaller sub-tasks, allowing LLM agents to learn and perform each task individually.\\n\\n**What is Task Decomposition?**\\n\\nTask decomposition involves dividing a complex task into smaller, more manageable sub-tasks. Each sub-task is designed to be solvable independently, with the ultimate goal of achieving the overall objective. This approach enables LLM agents to focus on one sub-task at a time, rather than trying to tackle the entire task simultaneously.\\n\\n**Benefits of Task Decomposition for LLM Agents**\\n\\nTask decomposition offers several benefits for LLM agents:\\n\\n1. **Improved Generalization**: By breaking down complex tasks into smaller sub-tasks, LLM agents can learn and generalize more effectively to new, unseen tasks.\\n2. **Increased Efficiency**: Task decomposition enables LLM agents to focus on one sub-task at a time, reducing the computational resources required to complete each task.\\n3. **Enhanced Robustness**: By learning individual sub-tasks, LLM agents can develop robust representations of language and improve their ability to handle noisy or ambiguous input.\\n\\n**Types of Task Decomposition**\\n\\nThere are several types of task decomposition that can be applied to LLM agents:\\n\\n1. **Hierarchical Task Decomposition**: This approach involves decomposing tasks into a hierarchical structure, with more abstract sub-tasks serving as the foundation for more specific ones.\\n2. **Task-Specific Decomposition**: In this approach, each sub-task is designed to address a specific aspect of the overall task, such as identifying entities or extracting relevant information.\\n3. **Hybrid Task Decomposition**: This approach combines hierarchical and task-specific decomposition techniques to create a flexible framework for task decomposition.\\n\\n**Challenges and Limitations**\\n\\nWhile task decomposition offers several benefits for LLM agents, there are also challenges and limitations to consider:\\n\\n1. **Task Complexity**: Complex tasks can be difficult to decompose into smaller sub-tasks, requiring careful consideration of the task's structure and requirements.\\n2. **Sub-Task Overfitting**: If sub-tasks are too specific or narrow, they may not generalize well to new tasks or environments.\\n3. **Over-Decomposition**: Decomposing a task too much can lead to loss of contextual information and reduced performance.\\n\\n**Conclusion**\\n\\nTask decomposition is a crucial aspect of artificial intelligence that enables Large Language Model (LLM) agents to perform complex tasks more effectively. By breaking down tasks into smaller sub-tasks, LLM agents can improve their generalization, efficiency, and robustness. However, task decomposition also presents challenges and limitations, such as task complexity, sub-task overfitting, and over-decomposition. Further research is needed to develop more effective task decomposition techniques for LLM agents.\\n\\n**Recommendations**\\n\\nTo overcome the challenges of task decomposition for LLM agents:\\n\\n1. **Develop More Effective Decomposition Techniques**: Researchers should focus on developing new task decomposition techniques that can handle complex tasks and sub-tasks.\\n2. **Improve Sub-Task Generalization**: Methods to improve sub-task generalization, such as using transfer learning or meta-learning, should be explored.\\n3. **Address Over-Decomposition**: Techniques to prevent over-decomposition, such as using hierarchical task decomposition, should be developed.\\n\\nBy addressing these challenges and limitations, researchers can develop more effective task decomposition techniques for LLM agents, enabling them to perform a wide range of cognitive and decision-making tasks with greater ease and accuracy.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] [60.57s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [60.57s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the following question based on this context:\\n\\n[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\\\nTask decomposition can be done (1) by LLM with simple prompting like \\\"Steps for XYZ.\\\\\\\\n1.\\\", \\\"What are the subgoals for achieving XYZ?\\\", (2) by using task-specific instructions; e.g. \\\"Write a story outline.\\\" for writing a novel, or (3) with human inputs.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\\\n\\\\nWeng, Lilian. (Jun 2023). LLM-powered Autonomous Agents. LilLog. https://lilianweng.github.io/posts/2023-06-23-agent/.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\\\"task\\\": task, \\\"id\\\", task_id, \\\"dep\\\": dependency_task_ids, \\\"args\\\": {\\\"text\\\": text, \\\"image\\\": URL, \\\"audio\\\": URL, \\\"video\\\": URL}}]. The \\\"dep\\\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \\\"-task_id\\\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\\\n\\\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\\\nInstruction:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='[4] Liu et al. LLM+P: Empowering Large Language Models with Optimal Planning Proficiency arXiv preprint arXiv:2304.11477 (2023).\\\\n[5] Yao et al. ReAct: Synergizing reasoning and acting in language models. ICLR 2023.\\\\n[6] Google Blog. Announcing ScaNN: Efficient Vector Similarity Search July 28, 2020.\\\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\\\n[8] Shinn & Labash. Reflexion: an autonomous agent with dynamic memory and self-reflection arXiv preprint arXiv:2303.11366 (2023).\\\\n[9] Laskin et al. In-context Reinforcement Learning with Algorithm Distillation ICLR 2023.\\\\n[10] Karpas et al. MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. arXiv preprint arXiv:2205.00445 (2022).'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.')]\\n\\nQuestion: what is task decomposition for LLM agents\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOllama] [49.96s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"According to the text, task decomposition for LLM (Large Language Model) agents involves breaking down a complicated task into smaller and simpler steps. This can be done in three ways:\\n\\n1. Using simple prompting, such as \\\"Steps for XYZ.\\\" or \\\"What are the subgoals for achieving XYZ.\\\"\\n2. Using task-specific instructions, such as \\\"Write a story outline\\\" for writing a novel.\\n3. With human inputs.\\n\\nTask decomposition is used to help LLM agents plan ahead and effectively explore the solution space, which remains challenging due to their limited context length and struggle with adjusting plans when faced with unexpected errors.\",\n",
      "        \"generation_info\": {\n",
      "          \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "          \"created_at\": \"2025-02-06T15:19:02.372361651Z\",\n",
      "          \"done\": true,\n",
      "          \"done_reason\": \"stop\",\n",
      "          \"total_duration\": 49955587987,\n",
      "          \"load_duration\": 23160991,\n",
      "          \"prompt_eval_count\": 1539,\n",
      "          \"prompt_eval_duration\": 40850000000,\n",
      "          \"eval_count\": 125,\n",
      "          \"eval_duration\": 9081000000,\n",
      "          \"message\": {\n",
      "            \"role\": \"assistant\",\n",
      "            \"content\": \"\",\n",
      "            \"images\": null,\n",
      "            \"tool_calls\": null\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"According to the text, task decomposition for LLM (Large Language Model) agents involves breaking down a complicated task into smaller and simpler steps. This can be done in three ways:\\n\\n1. Using simple prompting, such as \\\"Steps for XYZ.\\\" or \\\"What are the subgoals for achieving XYZ.\\\"\\n2. Using task-specific instructions, such as \\\"Write a story outline\\\" for writing a novel.\\n3. With human inputs.\\n\\nTask decomposition is used to help LLM agents plan ahead and effectively explore the solution space, which remains challenging due to their limited context length and struggle with adjusting plans when faced with unexpected errors.\",\n",
      "            \"response_metadata\": {\n",
      "              \"model\": \"llama3.2:3b-instruct-q5_K_M\",\n",
      "              \"created_at\": \"2025-02-06T15:19:02.372361651Z\",\n",
      "              \"done\": true,\n",
      "              \"done_reason\": \"stop\",\n",
      "              \"total_duration\": 49955587987,\n",
      "              \"load_duration\": 23160991,\n",
      "              \"prompt_eval_count\": 1539,\n",
      "              \"prompt_eval_duration\": 40850000000,\n",
      "              \"eval_count\": 125,\n",
      "              \"eval_duration\": 9081000000,\n",
      "              \"message\": {\n",
      "                \"lc\": 1,\n",
      "                \"type\": \"not_implemented\",\n",
      "                \"id\": [\n",
      "                  \"ollama\",\n",
      "                  \"_types\",\n",
      "                  \"Message\"\n",
      "                ],\n",
      "                \"repr\": \"Message(role='assistant', content='', images=None, tool_calls=None)\"\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-444561cb-6c6f-49eb-b8e3-1cef2e503a82-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1539,\n",
      "              \"output_tokens\": 125,\n",
      "              \"total_tokens\": 1664\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [110.53s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='According to the text, task decomposition for LLM (Large Language Model) agents involves breaking down a complicated task into smaller and simpler steps. This can be done in three ways:\\n\\n1. Using simple prompting, such as \"Steps for XYZ.\" or \"What are the subgoals for achieving XYZ.\"\\n2. Using task-specific instructions, such as \"Write a story outline\" for writing a novel.\\n3. With human inputs.\\n\\nTask decomposition is used to help LLM agents plan ahead and effectively explore the solution space, which remains challenging due to their limited context length and struggle with adjusting plans when faced with unexpected errors.', additional_kwargs={}, response_metadata={'model': 'llama3.2:3b-instruct-q5_K_M', 'created_at': '2025-02-06T15:19:02.372361651Z', 'done': True, 'done_reason': 'stop', 'total_duration': 49955587987, 'load_duration': 23160991, 'prompt_eval_count': 1539, 'prompt_eval_duration': 40850000000, 'eval_count': 125, 'eval_duration': 9081000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-444561cb-6c6f-49eb-b8e3-1cef2e503a82-0', usage_metadata={'input_tokens': 1539, 'output_tokens': 125, 'total_tokens': 1664})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_prompt_template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "actual_prompt = ChatPromptTemplate.from_template(actual_prompt_template)\n",
    "\n",
    "hyde_rag = (\n",
    "    {\n",
    "        'context': itemgetter('question') | hyde_chain | retriever,\n",
    "        'question': itemgetter('question')\n",
    "    }\n",
    "    | actual_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "hyde_rag.invoke({'question': question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
