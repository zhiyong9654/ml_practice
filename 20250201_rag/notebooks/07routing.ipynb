{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_10_and_11.ipynb\n",
    "\n",
    "some deviations from the source code because i dont wanna pay for embeddings from openai, or hit openai models. All openAI integration is replaced with ollama.\n",
    "\n",
    "I also removed langsmith integration. don't think it's needed. just a frontend for LLM debugging which i can achieve with `langchain.debug = True`\n",
    "\n",
    "For routing i'll deviate quite heavily from the notebook above as the methods applied are quite trivial to implement, will attempt to implement a custom example myself "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB routing\n",
    "In some case, we may want to look up a specific DB based on the question that's provided. Use an LLM to provide the routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_route_prompt_template = \"\"\"Given a user's question, determine the most likely type of database (choices are graph database, relational database, nosql database) that should be used to answer his query. If you are not able to determine the database type, respond with 'na'\n",
    "\n",
    "user_prompt:\n",
    "{user_prompt}\n",
    "\"\"\"\n",
    "\n",
    "db_route_prompt = ChatPromptTemplate.from_template(db_route_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chat model\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class PromptRouteModel(BaseModel):\n",
    "    answer: Literal['graph database', 'relational database', 'nosql database', 'na']\n",
    "    reason: str\n",
    "\n",
    "db_route_llm = ChatOllama(\n",
    "    model=\"llama3.2:3b-instruct-q5_K_M\",\n",
    "    temperature=0,\n",
    "    format=PromptRouteModel.model_json_schema()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_graph = \"I need to run weakly connect component algorithm to figure out a community of users\"\n",
    "user_prompt_relational = 'I need to use sql to look up how many orders a user has made'\n",
    "user_prompt_nosql = 'I need to do an index look up based on a given index and retrieve a bunch of unparsed data'\n",
    "user_prompt_na = 'who is mans best friend' # fail case\n",
    "user_prompt_na2 = 'tell me about gojo satoru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = db_route_prompt | db_route_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"graph database\",\n",
      "  \"reason\": \"The Weakly Connected Component (WCC) algorithm is typically used in graph theory and network analysis. Graph databases are well-suited for storing and querying complex networks, making them a good fit for this use case.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'user_prompt': user_prompt_graph}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"relational database\",\n",
      "  \"reason\": \"The question involves looking up data from a specific table (orders) and performing a count operation, which is typical of relational databases.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'user_prompt': user_prompt_relational}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"answer\": \"nosql database\", \"reason\": \"Index lookup is a common operation in NoSQL databases like MongoDB or Cassandra. Relational databases are not optimized for this type of query, while graph databases might be overkill for simple index lookups.\"}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'user_prompt': user_prompt_nosql}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"graph database\",\n",
      "  \"reason\": \"The question asks about a specific relationship ('best friend') which is often modeled as a graph in databases. Graph databases are well-suited for modeling complex relationships between entities.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# lol ok. the answer makes sense but still funny.\n",
    "print(chain.invoke({'user_prompt': user_prompt_na}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"na\",\n",
      "  \"reason\": \"The question is too open-ended and doesn't contain specific keywords related to a particular database structure. It could be answered using various types of databases.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({'user_prompt': user_prompt_na2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt routing\n",
    "\n",
    "Similar idea as DB routing, except instead of deciding on DB, you decide on different prompts. The code will be almost identical to above, so no point redoing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
